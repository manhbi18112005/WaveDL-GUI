# Fast Convergence Configuration
# ================================
# OneCycleLR for super-convergence training.
# Typically reaches good performance in fewer epochs.

model: cnn

# Hyperparameters - note higher LR for OneCycleLR
batch_size: 256
lr: 0.01
epochs: 100
patience: 50

# Training Components
loss: mse
optimizer: adamw
scheduler: onecycle

# Performance
precision: bf16
compile: true
seed: 2025
