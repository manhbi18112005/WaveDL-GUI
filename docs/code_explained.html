<!DOCTYPE html><html><head>
      <title>code_explained</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////Users/ductho/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.20/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="wavedl-framework---complete-beginners-guide">WaveDL Framework - Complete Beginner's Guide </h1>
<p>A comprehensive, beginner-friendly guide to understanding the WaveDL deep learning framework.</p>
<hr>
<h2 id="-table-of-contents">üìö Table of Contents </h2>
<ol>
<li><a href="#1-deep-learning-foundations">Deep Learning Foundations</a></li>
<li><a href="#2-what-wavedl-does">What WaveDL Does</a></li>
<li><a href="#3-project-architecture">Project Architecture</a></li>
<li><a href="#4-the-training-script-trainpy">The Training Script</a></li>
<li><a href="#5-neural-network-models">Neural Network Models</a></li>
<li><a href="#6-utility-modules">Utility Modules</a></li>
<li><a href="#7-glossary">Glossary</a></li>
</ol>
<hr>
<h2 id="1-deep-learning-foundations">1. Deep Learning Foundations </h2>
<p>Before diving into the code, let's understand the basics.</p>
<h3 id="11-what-is-deep-learning">1.1 What is Deep Learning? </h3>
<p><strong>Deep Learning</strong> is teaching computers to learn patterns from data, just like how you learn from examples.</p>
<blockquote>
<p><strong>üí° Analogy</strong>: Imagine learning to recognize cats. You look at thousands of cat pictures, and your brain learns to identify the patterns (ears, whiskers, fur). Neural networks do the same thing, but with numbers!</p>
</blockquote>
<h3 id="12-neural-network-structure">1.2 Neural Network Structure </h3>
<p><img src="images/neural_network_basics.png" alt="Neural Network Basics"></p>
<p>A neural network consists of:</p>
<table>
<thead>
<tr>
<th>Component</th>
<th>What It Does</th>
<th>Real-World Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Neuron</strong></td>
<td>Basic computing unit</td>
<td>A single brain cell</td>
</tr>
<tr>
<td><strong>Weight</strong></td>
<td>Connection strength</td>
<td>How strong a memory is</td>
</tr>
<tr>
<td><strong>Layer</strong></td>
<td>Group of neurons</td>
<td>A processing stage</td>
</tr>
<tr>
<td><strong>Activation</strong></td>
<td>Adds non-linearity</td>
<td>Decision threshold</td>
</tr>
</tbody>
</table>
<h3 id="13-the-training-loop">1.3 The Training Loop </h3>
<p>Learning happens through repeated cycles of prediction and correction:</p>
<p><img src="images/training_loop.png" alt="Training Loop"></p>
<p><strong>The Training Process:</strong></p>
<ol>
<li><strong>Forward Pass</strong>: Data flows through the network ‚Üí predictions made</li>
<li><strong>Loss Calculation</strong>: Compare predictions to true values ‚Üí how wrong are we?</li>
<li><strong>Backward Pass</strong>: Calculate gradients (which way to adjust weights)</li>
<li><strong>Weight Update</strong>: Optimizer adjusts weights to reduce loss</li>
</ol>
<blockquote>
<p><strong>üîë Key Insight</strong>: We repeat this process millions of times. Each time, the model gets slightly better!</p>
</blockquote>
<h3 id="14-gradient-descent-how-learning-works">1.4 Gradient Descent (How Learning Works) </h3>
<p><img src="images/gradient_descent.png" alt="Gradient Descent"></p>
<p>Think of it like rolling a ball down a hill:</p>
<ul>
<li>The <strong>loss landscape</strong> is the terrain</li>
<li>Your <strong>model weights</strong> are the ball's position</li>
<li><strong>Gradients</strong> show which direction is downhill</li>
<li>The <strong>learning rate</strong> controls step size</li>
<li>The <strong>goal</strong> is to reach the lowest point (minimum loss)</li>
</ul>
<h3 id="15-classification-vs-regression">1.5 Classification vs Regression </h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Output</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Classification</strong></td>
<td>Categories (discrete)</td>
<td>Is this email spam? (Yes/No)</td>
</tr>
<tr>
<td><strong>Regression</strong></td>
<td>Numbers (continuous)</td>
<td>What's the temperature? (23.5¬∞C)</td>
</tr>
</tbody>
</table>
<p><strong>WaveDL does regression</strong> - predicting continuous physical values from wave signals.</p>
<hr>
<h2 id="2-what-wavedl-does">2. What WaveDL Does </h2>
<h3 id="21-the-problem-were-solving">2.1 The Problem We're Solving </h3>
<p><strong>WaveDL</strong> trains neural networks to predict physical properties from ultrasonic guided wave signals.</p>
<p><strong>Real-World Application:</strong></p>
<ul>
<li>Non-destructive testing of materials</li>
<li>Measuring thickness, density, elastic properties</li>
<li>Quality control in manufacturing</li>
</ul>
<h3 id="22-input-and-output">2.2 Input and Output </h3>
<table>
<thead>
<tr>
<th></th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Input</strong></td>
<td>2D Wave Image (500 √ó 500 pixels)</td>
</tr>
<tr>
<td><strong>Output</strong></td>
<td>5 Physical Properties (thickness, density, velocity, etc.)</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="3-project-architecture">3. Project Architecture </h2>
<h3 id="31-file-structure">3.1 File Structure </h3>
<p><img src="images/project_structure.png" alt="Project Structure"></p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>WaveDL/
‚îú‚îÄ‚îÄ train.py              # üéØ Main entry point
‚îú‚îÄ‚îÄ models/               # üß† Neural network architectures
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package exports
‚îÇ   ‚îú‚îÄ‚îÄ registry.py       # Model lookup system
‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Template for all models
‚îÇ   ‚îú‚îÄ‚îÄ ratenet.py        # RATENet CNN model
‚îÇ   ‚îî‚îÄ‚îÄ _template.py      # Template for new models
‚îî‚îÄ‚îÄ utils/                # üîß Helper functions
    ‚îú‚îÄ‚îÄ __init__.py       # Package exports
    ‚îú‚îÄ‚îÄ data.py           # Data loading
    ‚îú‚îÄ‚îÄ metrics.py        # Performance measurement
    ‚îî‚îÄ‚îÄ distributed.py    # Multi-GPU helpers
</code></pre><h3 id="32-module-responsibilities">3.2 Module Responsibilities </h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>train.py</code></td>
<td>üéØ Orchestrates entire training process</td>
</tr>
<tr>
<td><code>models/registry.py</code></td>
<td>üìã Model lookup system (factory pattern)</td>
</tr>
<tr>
<td><code>models/base.py</code></td>
<td>üìê Abstract template for all models</td>
</tr>
<tr>
<td><code>models/ratenet.py</code></td>
<td>üß† The RATENet CNN architecture</td>
</tr>
<tr>
<td><code>utils/data.py</code></td>
<td>üíæ Memory-efficient data loading</td>
</tr>
<tr>
<td><code>utils/metrics.py</code></td>
<td>üìä Performance measurements</td>
</tr>
<tr>
<td><code>utils/distributed.py</code></td>
<td>üîó Multi-GPU coordination</td>
</tr>
</tbody>
</table>
<h3 id="33-complete-data-flow">3.3 Complete Data Flow </h3>
<p>This diagram shows how everything works together from command to results:</p>
<p><img src="images/data_flow.png" alt="WaveDL Complete Data Flow"></p>
<h3 id="34-component-interaction-sequence-diagram">3.4 Component Interaction (Sequence Diagram) </h3>
<p>This sequence diagram shows how the components communicate during training:</p>
<p><img src="images/sequence_diagram.png" alt="Sequence Diagram"></p>
<hr>
<h2 id="4-the-training-script-trainpy">4. The Training Script (<a href="http://train.py">train.py</a>) </h2>
<h3 id="41-command-line-interface">4.1 Command Line Interface </h3>
<p>When you run WaveDL, you can customize everything with flags:</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code>accelerate launch train.py <span class="token parameter variable">--model</span> ratenet <span class="token parameter variable">--batch_size</span> <span class="token number">128</span> <span class="token parameter variable">--wandb</span>
</code></pre><p><strong>All Available Options:</strong></p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--model</code></td>
<td>string</td>
<td><code>ratenet</code></td>
<td>Neural network architecture</td>
</tr>
<tr>
<td><code>--batch_size</code></td>
<td>int</td>
<td><code>128</code></td>
<td>Samples per training step</td>
</tr>
<tr>
<td><code>--lr</code></td>
<td>float</td>
<td><code>0.001</code></td>
<td>Learning rate</td>
</tr>
<tr>
<td><code>--epochs</code></td>
<td>int</td>
<td><code>1000</code></td>
<td>Maximum training epochs</td>
</tr>
<tr>
<td><code>--patience</code></td>
<td>int</td>
<td><code>20</code></td>
<td>Early stopping patience</td>
</tr>
<tr>
<td><code>--data_path</code></td>
<td>string</td>
<td><code>train_data.npz</code></td>
<td>Path to dataset</td>
</tr>
<tr>
<td><code>--resume</code></td>
<td>string</td>
<td><code>None</code></td>
<td>Checkpoint to resume from</td>
</tr>
<tr>
<td><code>--compile</code></td>
<td>flag</td>
<td>off</td>
<td>Enable torch.compile</td>
</tr>
<tr>
<td><code>--precision</code></td>
<td>string</td>
<td><code>bf16</code></td>
<td>Mixed precision type</td>
</tr>
<tr>
<td><code>--wandb</code></td>
<td>flag</td>
<td>off</td>
<td>Enable WandB logging</td>
</tr>
</tbody>
</table>
<h3 id="42-what-is-the-accelerator">4.2 What is the Accelerator? </h3>
<p>The <strong>Accelerator</strong> (from HuggingFace) simplifies multi-GPU training:</p>
<ul>
<li>‚úÖ Handles device placement automatically</li>
<li>‚úÖ Manages mixed precision (FP16/BF16)</li>
<li>‚úÖ Coordinates multiple GPUs (DDP)</li>
<li>‚úÖ You write normal PyTorch code</li>
</ul>
<blockquote>
<p><strong>üìù Note</strong>: DDP (Distributed Data Parallel) means training on multiple GPUs simultaneously. Each GPU gets different data, and results are combined. 4 GPUs = ~4x faster training!</p>
</blockquote>
<h3 id="43-key-training-concepts">4.3 Key Training Concepts </h3>
<h4 id="loss-function-mean-squared-error">Loss Function (Mean Squared Error) </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><table>
<thead>
<tr>
<th>Prediction</th>
<th>True Value</th>
<th>Error (Loss)</th>
</tr>
</thead>
<tbody>
<tr>
<td>7</td>
<td>5</td>
<td>(7-5)¬≤ = 4</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>(3-4)¬≤ = 1</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>(5-5)¬≤ = 0</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Lower loss = better predictions!</strong></p>
</blockquote>
<h4 id="optimizer-adamw">Optimizer (AdamW) </h4>
<p>The optimizer decides HOW to update weights based on gradients.</p>
<table>
<thead>
<tr>
<th>Optimizer</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SGD</strong></td>
<td>Simple, but slow</td>
</tr>
<tr>
<td><strong>Adam</strong></td>
<td>Fast, adaptive learning rates</td>
</tr>
<tr>
<td><strong>AdamW</strong></td>
<td>Adam + proper weight decay (best for most cases)</td>
</tr>
</tbody>
</table>
<h4 id="learning-rate-scheduler">Learning Rate Scheduler </h4>
<p><strong>ReduceLROnPlateau</strong>: If validation loss doesn't improve for N epochs, reduce learning rate by half. This helps escape local minima.</p>
<table>
<thead>
<tr>
<th>Epoch</th>
<th>Learning Rate</th>
<th>What Happened</th>
</tr>
</thead>
<tbody>
<tr>
<td>1-10</td>
<td>0.001</td>
<td>Normal training</td>
</tr>
<tr>
<td>11-20</td>
<td>0.0005</td>
<td>Reduced (stuck for 10 epochs)</td>
</tr>
<tr>
<td>21+</td>
<td>0.00025</td>
<td>Reduced again</td>
</tr>
</tbody>
</table>
<h4 id="early-stopping">Early Stopping </h4>
<p>Prevents overfitting by stopping when the model stops improving:</p>
<table>
<thead>
<tr>
<th>Epoch</th>
<th>Val Loss</th>
<th>Patience Counter</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td>0.050</td>
<td>0</td>
<td>New best! Reset counter</td>
</tr>
<tr>
<td>51</td>
<td>0.051</td>
<td>1</td>
<td>Worse, increment</td>
</tr>
<tr>
<td>52</td>
<td>0.052</td>
<td>2</td>
<td>Worse, increment</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>70</td>
<td>0.055</td>
<td>20</td>
<td><strong>STOP!</strong> (patience=20)</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="5-neural-network-models">5. Neural Network Models </h2>
<h3 id="51-the-registry-pattern">5.1 The Registry Pattern </h3>
<p>Think of it as a <strong>phone book</strong> for models:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Register a model</span>
<span class="token decorator annotation punctuation">@register_model</span><span class="token punctuation">(</span><span class="token string">"ratenet"</span><span class="token punctuation">)</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">RATENet</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment"># Look it up later</span>
model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"ratenet"</span><span class="token punctuation">)</span>  <span class="token comment"># Returns the RATENet class</span>
</code></pre><p><strong>Why use this?</strong></p>
<ul>
<li>‚úÖ Add new models without changing <a href="http://train.py">train.py</a></li>
<li>‚úÖ Switch models with <code>--model mymodel</code> flag</li>
<li>‚úÖ Clean separation of concerns</li>
</ul>
<h3 id="52-ratenet-architecture">5.2 RATENet Architecture </h3>
<p><strong>RATENet</strong> = <strong>R</strong>egression <strong>A</strong>rchitecture for <strong>T</strong>ime-domain <strong>E</strong>valuation <strong>Net</strong>work</p>
<p><img src="images/ratenet_architecture.png" alt="RATENet Architecture"></p>
<h3 id="53-key-architecture-components">5.3 Key Architecture Components </h3>
<h4 id="convolution-layers">Convolution Layers </h4>
<p>Convolution detects patterns by sliding a small filter across the image:</p>
<p><img src="images/convolution_operation.png" alt="Convolution Operation"></p>
<p><strong>What convolution does:</strong></p>
<ul>
<li>Slides a small filter (3√ó3) across the image</li>
<li>Detects patterns: edges, textures, shapes</li>
<li>Early layers ‚Üí simple patterns (edges)</li>
<li>Deep layers ‚Üí complex patterns (objects)</li>
</ul>
<h4 id="dilated-convolution">Dilated Convolution </h4>
<table>
<thead>
<tr>
<th>Type</th>
<th>Receptive Field</th>
<th>Computation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Normal (d=1)</td>
<td>3√ó3 = 9 pixels</td>
<td>9 multiplications</td>
</tr>
<tr>
<td>Dilated (d=2)</td>
<td>5√ó5 area</td>
<td>Still 9 multiplications!</td>
</tr>
<tr>
<td>Dilated (d=4)</td>
<td>9√ó9 area</td>
<td>Still 9 multiplications!</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>üí° Dilated convolution</strong> sees a larger area without more computation. It's like zooming out while keeping the same filter size!</p>
</blockquote>
<h4 id="cbam-attention">CBAM Attention </h4>
<p><img src="images/attention_mechanism.png" alt="CBAM Attention"></p>
<p>CBAM applies two types of attention:</p>
<ol>
<li><strong>Channel Attention</strong>: "Which feature channels are most important?"</li>
<li><strong>Spatial Attention</strong>: "Which spatial locations matter?"</li>
</ol>
<h4 id="skip-connections">Skip Connections </h4>
<p><strong>Why skip connections?</strong></p>
<ul>
<li>‚úÖ Deep layers lose fine details</li>
<li>‚úÖ Skip connections preserve them</li>
<li>‚úÖ Combine "what" (deep) with "where" (shallow)</li>
</ul>
<hr>
<h2 id="6-utility-modules">6. Utility Modules </h2>
<h3 id="61-data-loading-utilsdatapy">6.1 Data Loading (utils/data.py) </h3>
<h4 id="the-memory-problem">The Memory Problem </h4>
<p><img src="images/memory_mapping.png" alt="Memory Mapping"></p>
<p><strong>Traditional Loading:</strong></p>
<ul>
<li>Load 10GB dataset into RAM</li>
<li>üí• Out of memory crash!</li>
</ul>
<p><strong>Memory Mapping Solution:</strong></p>
<ul>
<li>Keep data on disk</li>
<li>Load only what you need, when you need it</li>
<li>‚úÖ Works with any dataset size!</li>
</ul>
<blockquote>
<p><strong>üí° Analogy</strong>: Memory mapping is like a library. Instead of borrowing all 10,000 books at once, you read one page when you need it!</p>
</blockquote>
<h3 id="62-distributed-utilities-utilsdistributedpy">6.2 Distributed Utilities (utils/distributed.py) </h3>
<p><strong>The Problem:</strong> With multiple GPUs, each runs independently. If GPU 0 decides to stop training but others don't know, you get a <strong>deadlock</strong>.</p>
<p><strong>The Solution:</strong> <code>broadcast_early_stop()</code> - GPU 0 broadcasts its decision to all other GPUs so they all stop together.</p>
<h3 id="63-metrics-utilsmetricspy">6.3 Metrics (utils/metrics.py) </h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Range</th>
<th>Meaning</th>
<th>Ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MSE Loss</strong></td>
<td>0 ‚Üí ‚àû</td>
<td>Average squared error</td>
<td>Lower is better</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>0 ‚Üí ‚àû</td>
<td>Average absolute error</td>
<td>Lower is better</td>
</tr>
<tr>
<td><strong>R¬≤ Score</strong></td>
<td>-‚àû ‚Üí 1</td>
<td>Variance explained</td>
<td>1.0 = perfect</td>
</tr>
<tr>
<td><strong>Pearson</strong></td>
<td>-1 ‚Üí 1</td>
<td>Correlation</td>
<td>1.0 = perfect</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="7-glossary">7. Glossary </h2>
<h3 id="training-terms">Training Terms </h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Batch</strong></td>
<td>Group of samples processed together (e.g., 128 images)</td>
</tr>
<tr>
<td><strong>Epoch</strong></td>
<td>One complete pass through all training data</td>
</tr>
<tr>
<td><strong>Forward Pass</strong></td>
<td>Input ‚Üí Model ‚Üí Prediction</td>
</tr>
<tr>
<td><strong>Backward Pass</strong></td>
<td>Calculate gradients for weight updates</td>
</tr>
<tr>
<td><strong>Gradient</strong></td>
<td>Direction and magnitude to adjust weights</td>
</tr>
<tr>
<td><strong>Learning Rate</strong></td>
<td>Step size for weight updates</td>
</tr>
</tbody>
</table>
<h3 id="model-terms">Model Terms </h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Neuron</strong></td>
<td>Single computing unit in a neural network</td>
</tr>
<tr>
<td><strong>Weight</strong></td>
<td>Learnable parameter connecting neurons</td>
</tr>
<tr>
<td><strong>Layer</strong></td>
<td>Group of neurons at the same depth</td>
</tr>
<tr>
<td><strong>Activation</strong></td>
<td>Non-linear function (ReLU, LeakyReLU, etc.)</td>
</tr>
</tbody>
</table>
<h3 id="architecture-terms">Architecture Terms </h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CNN</strong></td>
<td>Convolutional Neural Network - specialized for images</td>
</tr>
<tr>
<td><strong>Convolution</strong></td>
<td>Sliding filter that detects patterns</td>
</tr>
<tr>
<td><strong>Pooling</strong></td>
<td>Reduce spatial dimensions (MaxPool, AvgPool)</td>
</tr>
<tr>
<td><strong>Skip Connection</strong></td>
<td>Direct path bypassing layers</td>
</tr>
<tr>
<td><strong>Attention</strong></td>
<td>Mechanism to focus on important parts</td>
</tr>
</tbody>
</table>
<h3 id="distributed-training">Distributed Training </h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DDP</strong></td>
<td>Distributed Data Parallel - training on multiple GPUs</td>
</tr>
<tr>
<td><strong>Rank</strong></td>
<td>GPU identifier (Rank 0 is the main process)</td>
</tr>
<tr>
<td><strong>Mixed Precision</strong></td>
<td>Using FP16/BF16 to save memory and speed up</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="-quick-reference">üöÄ Quick Reference </h2>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token comment"># Basic training</span>
accelerate launch train.py <span class="token parameter variable">--model</span> ratenet <span class="token parameter variable">--wandb</span>

<span class="token comment"># List available models</span>
python train.py <span class="token parameter variable">--list_models</span>

<span class="token comment"># Multi-GPU training</span>
accelerate launch <span class="token parameter variable">--num_processes</span><span class="token operator">=</span><span class="token number">4</span> train.py <span class="token parameter variable">--model</span> ratenet <span class="token parameter variable">--wandb</span>

<span class="token comment"># Resume training</span>
accelerate launch train.py <span class="token parameter variable">--model</span> ratenet <span class="token parameter variable">--resume</span> best_checkpoint

<span class="token comment"># Full custom configuration</span>
accelerate launch train.py <span class="token punctuation">\</span>
    <span class="token parameter variable">--model</span> ratenet <span class="token punctuation">\</span>
    <span class="token parameter variable">--batch_size</span> <span class="token number">64</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--lr</span> <span class="token number">0.0005</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--epochs</span> <span class="token number">500</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--patience</span> <span class="token number">30</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--precision</span> bf16 <span class="token punctuation">\</span>
    <span class="token parameter variable">--compile</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--wandb</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--project_name</span> <span class="token string">"MyProject"</span>
</code></pre><hr>
<p><em>WaveDL Framework Documentation v3.0.0</em></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>